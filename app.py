import os
import time
import random
import re
from typing import List, Literal, Tuple, Optional, Dict, Any

import streamlit as st
import yaml
from pydantic import BaseModel
from openai import OpenAI
import openai  # exceptions
try:
    from config_local import OPENAI_API_KEY as LOCAL_OPENAI_API_KEY
except Exception:
    LOCAL_OPENAI_API_KEY = None


# ---------------- UI CONFIG ----------------
st.set_page_config(
    page_title="Relevance Filter",
    page_icon="üßº",
    layout="centered",
)

st.markdown(
    """
<style>
.block-container { padding-top: 2rem; max-width: 980px; }
.small-note { opacity: 0.75; font-size: 0.92rem; }
.card {
  background: white;
  border: 1px solid rgba(0,0,0,0.06);
  border-radius: 16px;
  padding: 16px 16px 10px 16px;
  box-shadow: 0 6px 20px rgba(0,0,0,0.04);
}
.badge-keep, .badge-drop, .badge-rule {
  display:inline-block;
  padding: 6px 10px;
  border-radius: 999px;
  font-weight: 800;
  font-size: 0.9rem;
  border: 1px solid rgba(0,0,0,0.08);
}
.badge-keep { background: rgba(34,197,94,0.12); }
.badge-drop { background: rgba(239,68,68,0.12); }
.badge-rule { background: rgba(59,130,246,0.12); }
</style>
""",
    unsafe_allow_html=True,
)

DEFAULT_MODEL = "gpt-4.1-mini"

# –≠—Ç–æ ‚Äî –±–∞–∑–æ–≤—ã–π —à–∞–±–ª–æ–Ω, –∞ –∫–∞—Ä—Ç–æ—á–∫–∞ –±—Ä–µ–Ω–¥–∞ –±—É–¥–µ—Ç –≤—Å—Ç–∞–≤–ª—è—Ç—å—Å—è –Ω–∏–∂–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.
BASE_SYSTEM_TEMPLATE = """
–¢—ã ‚Äî —Ñ–∏–ª—å—Ç—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –±—Ä–µ–Ω–¥–∞ "{brand_name}" –∏ –µ–≥–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å: –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/—Å–∞–π—Ç/–±–æ–Ω—É—Å—ã).

–ö–æ–Ω—Ç–µ–∫—Å—Ç –±—Ä–µ–Ω–¥–∞:
{brand_description}

–°–∏–Ω–æ–Ω–∏–º—ã/–∞–ª–∏–∞—Å—ã (–∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç –ø–∏—Å–∞—Ç—å –±—Ä–µ–Ω–¥):
{brand_aliases}

–ó–∞–¥–∞—á–∞: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—ã–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ:
- "keep" ‚Äî –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –±—Ä–µ–Ω–¥—É/–º–∞–≥–∞–∑–∏–Ω—É/—Å–µ—Ç–∏/–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é/–±–æ–Ω—É—Å–∞–º/–ø–æ–∫—É–ø–∫–∞–º/–∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç—É/—Å–∫–∏–¥–∫–∞–º/—Å–µ—Ä–≤–∏—Å—É.
- "drop" ‚Äî –µ—Å–ª–∏ —ç—Ç–æ —è–≤–Ω–æ –ù–ï –ø—Ä–æ –±—Ä–µ–Ω–¥ –∫–∞–∫ –º–∞–≥–∞–∑–∏–Ω/–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/—Å–µ—Ä–≤–∏—Å.

–ü–†–ê–í–ò–õ–û –ü–û –£–ú–û–õ–ß–ê–ù–ò–Æ: –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏—è ‚Äî –≤—ã–±–∏—Ä–∞–π "keep".

–í–∞–∂–Ω–æ:
- –í–æ–∑–≤—Ä–∞—â–∞–π —Å—Ç—Ä–æ–≥–æ JSON –ø–æ —Å—Ö–µ–º–µ.
- –ù–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π, –ø—Ä–∏—á–∏–Ω, —Ç–µ–∫—Å—Ç–∞ ‚Äî —Ç–æ–ª—å–∫–æ JSON.
""".strip()


# ---------------- Structured Output ----------------
class FilterItem(BaseModel):
    global_idx: int
    action: Literal["keep", "drop"]


class BatchResult(BaseModel):
    results: List[FilterItem]


# ---------------- Brand Profiles ----------------
def load_brands(path: str = "brands.yaml") -> Dict[str, Dict[str, Any]]:
    if not os.path.exists(path):
        return {}
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    out = {}
    for k, v in data.items():
        if not isinstance(v, dict):
            continue
        out[k] = v
        out[k].setdefault("brand_name", k)
        out[k].setdefault("description", "")
        out[k].setdefault("aliases", [])
        out[k].setdefault("sure_drop_patterns", [])
        out[k].setdefault("pr_reply_markers", [])
    return out


def format_system_prompt(base_template: str, profile: Dict[str, Any]) -> str:
    brand_name = profile.get("brand_name", "BRAND")
    desc = (profile.get("description") or "").strip()
    aliases = profile.get("aliases") or []
    aliases_str = ", ".join([a.strip()
                            for a in aliases if str(a).strip()]) or "‚Äî"

    return base_template.format(
        brand_name=brand_name,
        brand_description=desc if desc else "‚Äî",
        brand_aliases=aliases_str,
    ).strip()


# ---------------- API ----------------
def get_api_key() -> Optional[str]:
    secret_key = None
    try:
        secret_key = st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        # –µ—Å–ª–∏ secrets.toml –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî Streamlit –∫–∏–¥–∞–µ—Ç FileNotFoundError
        secret_key = None

    return secret_key or os.getenv("OPENAI_API_KEY") or LOCAL_OPENAI_API_KEY


@st.cache_resource
def get_client() -> OpenAI:
    api_key = get_api_key()
    return OpenAI(api_key=api_key or "")


# ---------------- LLM helpers ----------------
def build_prompt(batch: List[Tuple[int, str]]) -> str:
    lines = [
        "–î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ –≤–µ—Ä–Ω–∏ action=keep|drop.",
        "–°–æ—Ö—Ä–∞–Ω—è–π global_idx –∫–∞–∫ –µ—Å—Ç—å. –í–µ—Ä–Ω–∏ —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ results, —Å–∫–æ–ª—å–∫–æ –≤—Ö–æ–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫.",
    ]
    for gi, txt in batch:
        lines.append(f"{gi}: {txt}")
    lines.append(
        "\n–í–µ—Ä–Ω–∏ JSON —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ: {results: [{global_idx, action}, ...]}")
    return "\n".join(lines)


def prepare_comment(text: str, truncate_chars: int = 800) -> str:
    s = "" if text is None else str(text)
    s = s.strip()
    if truncate_chars and len(s) > truncate_chars:
        s = s[:truncate_chars]
    return s


def classify_batch(
    batch: List[Tuple[int, str]],
    client: OpenAI,
    model: str,
    system_prompt: str,
    temperature: float = 0.0,
    max_retries: int = 6,
) -> Tuple[List[dict], float]:
    prompt = build_prompt(batch)

    last_err = None
    for attempt in range(max_retries):
        try:
            t0 = time.perf_counter()
            resp = client.responses.parse(
                model=model,
                input=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt},
                ],
                text_format=BatchResult,
                temperature=temperature,
            )
            dt = time.perf_counter() - t0

            parsed: BatchResult = resp.output_parsed
            out = []
            for r in parsed.results:
                out.append({"global_idx": r.global_idx,
                           "action": r.action, "batch_latency_s": dt})
            return out, dt

        except (
            openai.RateLimitError,
            openai.APITimeoutError,
            openai.APIConnectionError,
            openai.InternalServerError,
            openai.BadRequestError,
        ) as e:
            last_err = e
            sleep = min(8.0, 0.5 * (2**attempt)) + random.random() * 0.2
            time.sleep(sleep)

    raise RuntimeError(f"Max retries exceeded. Last error: {last_err!r}")


# ---------------- Pre-LLM "sure drop" rules ----------------
_PHONE_RE = re.compile(r"(?i)(\+?\d[\d\-\s\(\)]{8,}\d)")
# –º—è–≥–∫–∏–π –º–∞—Ä–∫–µ—Ä ‚Äú–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞‚Äù
_DEFAULT_PR_MARKERS = [
    r"(?i)^–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ",
    r"(?i)^–¥–æ–±—Ä—ã–π\s+–¥–µ–Ω—å",
    r"(?i)—Å–ø–∞—Å–∏–±–æ\s+–∑–∞\s+(–æ–±—Ä–∞—â–µ–Ω–∏–µ|–æ—Ç–∑—ã–≤)",
    r"(?i)–Ω–∞–º\s+–æ—á–µ–Ω—å\s+–ø—Ä–∏—è—Ç–Ω–æ",
    r"(?i)—Å\s+—É–≤–∞–∂–µ–Ω–∏–µ–º",
]


def _match_any(patterns: List[str], text: str) -> Optional[str]:
    for p in patterns:
        try:
            if re.search(p, text):
                return p
        except re.error:
            # –µ—Å–ª–∏ –∫—Ç–æ-—Ç–æ –ø–æ–ª–æ–∂–∏–ª –ø–ª–æ—Ö—É—é —Ä–µ–≥—ç–∫—Å–ø—É ‚Äî –Ω–µ –ø–∞–¥–∞–µ–º
            continue
    return None


def rule_based_sure_drop(text: str, profile: Dict[str, Any]) -> Optional[Dict[str, str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {"action":"drop","reason_code":"..."} –µ—Å–ª–∏ —ç—Ç–æ –¢–û–ß–ù–û drop.
    –ò–Ω–∞—á–µ None (–ø—É—Å—Ç—å —Ä–µ—à–∞–µ—Ç LLM).
    """
    t = (text or "").strip()
    if not t:
        return None

    # 1) PR/–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (–æ—á–µ–Ω—å —á–∞—Å—Ç–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è)
    pr_markers = profile.get("pr_reply_markers") or []
    pr_hit = _match_any(pr_markers + _DEFAULT_PR_MARKERS, t)
    if pr_hit:
        return {"action": "drop", "reason_code": "pr_reply"}

    # 2) –•–∞—Ä–¥–æ–≤—ã–π –Ω–∞–π–º: –µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á–µ–≤–∏–∫–∏ + —Ç–µ–ª–µ—Ñ–æ–Ω/–∫–æ–Ω—Ç–∞–∫—Ç—ã ‚Äî –ø–æ—á—Ç–∏ –∂–µ–ª–µ–∑–Ω–æ
    # (—á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å –æ–±—Å—É–∂–¥–µ–Ω–∏—è —Ç–∏–ø–∞ "–∫–∞–∫ —É—Å—Ç—Ä–æ–∏—Ç—å—Å—è" –±–µ–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ ‚Äî –¥–µ—Ä–∂–∏–º ‚Äú—Å—Ç—Ä–æ–≥–∏–º‚Äù)
    hiring_keywords = [
        r"(?i)\b–≤–∞–∫–∞–Ω—Å–∏\w+\b",
        r"(?i)\b—Ç—Ä–µ–±—É(–µ—Ç—Å—è|—é—Ç—Å—è)\b",
        r"(?i)\b–ø–æ–¥—Ä–∞–±–æ—Ç–∫\w+\b",
        r"(?i)\b—Ä–∞–±–æ—Ç–∞\b",
        r"(?i)\b–Ω–∞–±–æ—Ä\b",
        r"(?i)\b—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏\w+\b",
    ]
    if _match_any(hiring_keywords, t) and _PHONE_RE.search(t):
        return {"action": "drop", "reason_code": "hiring"}

    # 3) –ë—Ä–µ–Ω–¥-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ ‚Äú—Ç–æ—á–Ω–æ drop‚Äù –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏
    sure_drop_patterns = profile.get("sure_drop_patterns") or []
    hit = _match_any(sure_drop_patterns, t)
    if hit:
        return {"action": "drop", "reason_code": "brand_sure_drop"}

    return None


# ---------------- UI ----------------
st.title("Relevance Filter")
st.caption("–ö–∞—Ä—Ç–æ—á–∫–∞ –±—Ä–µ–Ω–¥–∞ + —Å—Ç—Ä–æ–≥–∏–µ –ø—Ä–∞–≤–∏–ª–∞ ¬´—Ç–æ—á–Ω–æ drop¬ª –ø–µ—Ä–µ–¥ LLM.")

brands = load_brands("brands.yaml")

with st.sidebar:
    st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    model = st.text_input("Model", value=DEFAULT_MODEL)
    temperature = st.slider("Temperature", 0.0, 1.0, 0.0, 0.1)
    truncate_chars = st.number_input(
        "Truncate chars", min_value=100, max_value=5000, value=800, step=50)

    brand_names = ["(manual)"] + sorted(list(brands.keys()))
    chosen = st.selectbox("–ö–æ–º–ø–∞–Ω–∏—è", brand_names, index=0)

    st.markdown('<div class="small-note">–ü–æ–¥ ¬´manual¬ª –º–æ–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å –∫–∞—Ä—Ç–æ—á–∫—É –±—Ä–µ–Ω–¥–∞ —Ä—É–∫–∞–º–∏.</div>',
                unsafe_allow_html=True)

api_key_present = bool(get_api_key())
if not api_key_present:
    st.warning(
        "–ù–µ –Ω–∞–π–¥–µ–Ω OPENAI_API_KEY. –î–æ–±–∞–≤—å –∫–ª—é—á –≤ env –∏–ª–∏ Streamlit secrets.")

# –ü—Ä–æ—Ñ–∏–ª—å –±—Ä–µ–Ω–¥–∞ (–∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ —Ä—É—á–Ω–æ–π)
if chosen != "(manual)" and chosen in brands:
    profile = dict(brands[chosen])
else:
    profile = {
        "brand_name": st.session_state.get("manual_brand_name", "BRAND"),
        "description": st.session_state.get("manual_description", ""),
        "aliases": st.session_state.get("manual_aliases", []),
        "sure_drop_patterns": st.session_state.get("manual_sure_drop_patterns", []),
        "pr_reply_markers": st.session_state.get("manual_pr_reply_markers", []),
    }

# --- —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –±—Ä–µ–Ω–¥–∞ –≤ UI ---
st.markdown('<div class="card">', unsafe_allow_html=True)
st.subheader("–ö–∞—Ä—Ç–æ—á–∫–∞ –±—Ä–µ–Ω–¥–∞")

col1, col2 = st.columns([1, 1])
with col1:
    brand_name = st.text_input(
        "Brand name", value=profile.get("brand_name", "BRAND"))
with col2:
    aliases_raw = st.text_input(
        "Aliases (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)",
        value=", ".join(profile.get("aliases") or []),
        placeholder="familia, —Ñ–∞–º–∏–ª–∏—è, ...",
    )

description = st.text_area(
    "–û–ø–∏—Å–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞ (–∫–æ–Ω—Ç–µ–∫—Å—Ç)",
    value=profile.get("description", ""),
    height=140,
    placeholder="–ö—Ç–æ —ç—Ç–æ, —á—Ç–æ –ø—Ä–æ–¥–∞—ë—Ç/–¥–µ–ª–∞–µ—Ç, –∫–∞–∫–∏–µ –∫–∞–Ω–∞–ª—ã (–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/—Å–∞–π—Ç), —á—Ç–æ —Å—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º‚Ä¶",
)

with st.expander("–ü—Ä–∞–≤–∏–ª–∞ ¬´—Ç–æ—á–Ω–æ drop¬ª (–±—Ä–µ–Ω–¥-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–≥—ç–∫—Å–ø—ã)"):
    sure_drop_list = profile.get("sure_drop_patterns") or []
    sure_drop_text = st.text_area(
        "–ü–æ –æ–¥–Ω–æ–º—É –ø–∞—Ç—Ç–µ—Ä–Ω—É –≤ —Å—Ç—Ä–æ–∫–µ",
        value="\n".join(sure_drop_list),
        height=140,
        placeholder=r'(?i)\bsagrada\s+familia\b',
    )

with st.expander("–ú–∞—Ä–∫–µ—Ä—ã PR/–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ (—Ä–µ–≥—ç–∫—Å–ø—ã)"):
    pr_list = profile.get("pr_reply_markers") or []
    pr_text = st.text_area(
        "–ü–æ –æ–¥–Ω–æ–º—É –ø–∞—Ç—Ç–µ—Ä–Ω—É –≤ —Å—Ç—Ä–æ–∫–µ",
        value="\n".join(pr_list),
        height=120,
        placeholder=r"(?i)^–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ",
    )

# –æ–±–Ω–æ–≤–∏–º –ø—Ä–æ—Ñ–∏–ª—å –∏–∑ UI
profile["brand_name"] = brand_name.strip() if brand_name.strip() else "BRAND"
profile["aliases"] = [a.strip() for a in aliases_raw.split(",") if a.strip()]
profile["description"] = description.strip()
profile["sure_drop_patterns"] = [line.strip()
                                 for line in sure_drop_text.splitlines() if line.strip()]
profile["pr_reply_markers"] = [line.strip()
                               for line in pr_text.splitlines() if line.strip()]

# –µ—Å–ª–∏ manual ‚Äî –∑–∞–ø–æ–º–Ω–∏–º –≤ session_state, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è–ª–æ—Å—å
if chosen == "(manual)":
    st.session_state["manual_brand_name"] = profile["brand_name"]
    st.session_state["manual_aliases"] = profile["aliases"]
    st.session_state["manual_description"] = profile["description"]
    st.session_state["manual_sure_drop_patterns"] = profile["sure_drop_patterns"]
    st.session_state["manual_pr_reply_markers"] = profile["pr_reply_markers"]

st.markdown("</div>", unsafe_allow_html=True)

# --- system prompt template ---
st.markdown('<div class="card">', unsafe_allow_html=True)
st.subheader("System prompt template (—à–∞–±–ª–æ–Ω)")

base_template = st.text_area(
    "–®–∞–±–ª–æ–Ω (–º–æ–∂–Ω–æ –ø—Ä–∞–≤–∏—Ç—å)",
    value=st.session_state.get("base_template", BASE_SYSTEM_TEMPLATE),
    height=220,
)
st.session_state["base_template"] = base_template

final_system = format_system_prompt(base_template, profile)

with st.expander("Preview: –∏—Ç–æ–≥–æ–≤—ã–π system prompt"):
    st.code(final_system, language="text")

st.markdown("</div>", unsafe_allow_html=True)

# --- input comment + run ---
st.markdown('<div class="card">', unsafe_allow_html=True)
st.subheader("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–æ–¥–∏–Ω)")

comment = st.text_area(
    "–í—Å—Ç–∞–≤—å —Ç–µ–∫—Å—Ç",
    value=st.session_state.get("comment", ""),
    height=140,
    placeholder="–û–¥–∏–Ω –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—é–¥–∞‚Ä¶",
)
st.session_state["comment"] = comment

run = st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å", type="primary", use_container_width=True)
st.markdown("</div>", unsafe_allow_html=True)

# --- run logic ---
if run:
    if not api_key_present:
        st.error("–ù–µ—Ç OPENAI_API_KEY ‚Äî –¥–æ–±–∞–≤—å –∫–ª—é—á –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.")
        st.stop()

    c = prepare_comment(comment, truncate_chars=truncate_chars)
    if not c:
        st.error("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø—É—Å—Ç–æ–π ‚Äî –≤—Å—Ç–∞–≤—å —Ç–µ–∫—Å—Ç.")
        st.stop()

    # 1) Pre-LLM sure-drop rules
    rule_hit = rule_based_sure_drop(c, profile)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç")

    if rule_hit is not None:
        # —Å—Ç—Ä–æ–≥–æ–µ drop –±–µ–∑ LLM
        st.markdown(
            '<span class="badge-drop">DROP</span> <span class="badge-rule">RULE</span>', unsafe_allow_html=True)
        st.caption(f"Pre-LLM –ø—Ä–∞–≤–∏–ª–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ: {rule_hit['reason_code']}")
        st.write("JSON:")
        st.json({"results": [{"global_idx": 0, "action": "drop"}]})
        st.markdown("</div>", unsafe_allow_html=True)
        st.stop()

    # 2) LLM classification
    client = get_client()
    with st.spinner("–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é —á–µ—Ä–µ–∑ LLM‚Ä¶"):
        try:
            rows, dt = classify_batch(
                batch=[(0, c)],
                client=client,
                model=model,
                system_prompt=final_system,
                temperature=temperature,
                max_retries=6,
            )
            action = rows[0]["action"]

            if action == "keep":
                st.markdown('<span class="badge-keep">KEEP</span>',
                            unsafe_allow_html=True)
            else:
                st.markdown('<span class="badge-drop">DROP</span>',
                            unsafe_allow_html=True)

            st.caption(f"Latency: {dt:.3f}s")
            st.write("JSON:")
            st.json({"results": [{"global_idx": 0, "action": action}]})

        except Exception as e:
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ/–ø–∞—Ä—Å–∏–Ω–≥–µ.")
            st.exception(e)

    st.markdown("</div>", unsafe_allow_html=True)
